{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18d004",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install -q mediapipe\n",
    "wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386b9fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -q -O image.jpg https://storage.googleapis.com/mediapipe-tasks/hand_landmarker/woman_hands.jpg\n",
    "\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "# cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4933fff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m python\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vision\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10.11\\lib\\site-packages\\mediapipe\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtasks\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m framework\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gpu\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10.11\\lib\\site-packages\\mediapipe\\tasks\\python\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10.11\\lib\\site-packages\\mediapipe\\tasks\\python\\audio\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classifier\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_embedder\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m AudioClassifier \u001b[38;5;241m=\u001b[39m \u001b[43maudio_classifier\u001b[49m\u001b[38;5;241m.\u001b[39mAudioClassifier\n\u001b[0;32m     22\u001b[0m AudioClassifierOptions \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifierOptions\n\u001b[0;32m     23\u001b[0m AudioClassifierResult \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifierResult\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an HandLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                       num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(\"image.jpg\")\n",
    "\n",
    "# STEP 4: Detect hand landmarks from the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the classification result. In this case, visualize it.\n",
    "# annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "# cv2.imshow('img',annotated_image)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf3b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\laragon\\bin\\python\\python-3.10.11\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0738 - loss: 3.5139 - val_accuracy: 0.2819 - val_loss: 3.0440\n",
      "Epoch 2/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2040 - loss: 2.9605 - val_accuracy: 0.4093 - val_loss: 2.5234\n",
      "Epoch 3/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3910 - loss: 2.4122 - val_accuracy: 0.5521 - val_loss: 1.9830\n",
      "Epoch 4/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4259 - loss: 2.0399 - val_accuracy: 0.6293 - val_loss: 1.5410\n",
      "Epoch 5/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5308 - loss: 1.6835 - val_accuracy: 0.7066 - val_loss: 1.2160\n",
      "Epoch 6/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5914 - loss: 1.4113 - val_accuracy: 0.7490 - val_loss: 0.9896\n",
      "Epoch 7/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6893 - loss: 1.1387 - val_accuracy: 0.7413 - val_loss: 0.8280\n",
      "Epoch 8/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7041 - loss: 1.0301 - val_accuracy: 0.7761 - val_loss: 0.7186\n",
      "Epoch 9/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7268 - loss: 0.9222 - val_accuracy: 0.8147 - val_loss: 0.6468\n",
      "Epoch 10/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.8698 - val_accuracy: 0.8263 - val_loss: 0.5792\n",
      "Epoch 11/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 0.7116 - val_accuracy: 0.8224 - val_loss: 0.5436\n",
      "Epoch 12/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7611 - loss: 0.7202 - val_accuracy: 0.8417 - val_loss: 0.4980\n",
      "Epoch 13/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.6754 - val_accuracy: 0.8610 - val_loss: 0.4658\n",
      "Epoch 14/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8083 - loss: 0.6399 - val_accuracy: 0.8533 - val_loss: 0.4477\n",
      "Epoch 15/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8188 - loss: 0.5899 - val_accuracy: 0.8687 - val_loss: 0.4211\n",
      "Epoch 16/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.5395 - val_accuracy: 0.8610 - val_loss: 0.4105\n",
      "Epoch 17/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8760 - loss: 0.4419 - val_accuracy: 0.8726 - val_loss: 0.3928\n",
      "Epoch 18/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8442 - loss: 0.4796 - val_accuracy: 0.8803 - val_loss: 0.3906\n",
      "Epoch 19/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.5176 - val_accuracy: 0.8803 - val_loss: 0.3683\n",
      "Epoch 20/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8518 - loss: 0.4619 - val_accuracy: 0.8803 - val_loss: 0.3501\n",
      "Epoch 21/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8322 - loss: 0.4956 - val_accuracy: 0.8803 - val_loss: 0.3439\n",
      "Epoch 22/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8617 - loss: 0.4177 - val_accuracy: 0.8803 - val_loss: 0.3371\n",
      "Epoch 23/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8709 - loss: 0.3929 - val_accuracy: 0.8842 - val_loss: 0.3270\n",
      "Epoch 24/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8838 - loss: 0.3556 - val_accuracy: 0.8880 - val_loss: 0.3223\n",
      "Epoch 25/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8845 - loss: 0.3361 - val_accuracy: 0.8958 - val_loss: 0.3178\n",
      "Epoch 26/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8511 - loss: 0.3880 - val_accuracy: 0.8919 - val_loss: 0.3206\n",
      "Epoch 27/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8907 - loss: 0.3352 - val_accuracy: 0.8919 - val_loss: 0.3101\n",
      "Epoch 28/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8860 - loss: 0.3294 - val_accuracy: 0.8958 - val_loss: 0.3172\n",
      "Epoch 29/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.3569 - val_accuracy: 0.8919 - val_loss: 0.3098\n",
      "Epoch 30/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8631 - loss: 0.3912 - val_accuracy: 0.9035 - val_loss: 0.2966\n",
      "Epoch 31/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8799 - loss: 0.3399 - val_accuracy: 0.8958 - val_loss: 0.3081\n",
      "Epoch 32/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8841 - loss: 0.3519 - val_accuracy: 0.8996 - val_loss: 0.2977\n",
      "Epoch 33/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8805 - loss: 0.3309 - val_accuracy: 0.9035 - val_loss: 0.2913\n",
      "Epoch 34/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9015 - loss: 0.3076 - val_accuracy: 0.9112 - val_loss: 0.2886\n",
      "Epoch 35/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8872 - loss: 0.2967 - val_accuracy: 0.9112 - val_loss: 0.2780\n",
      "Epoch 36/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8987 - loss: 0.2821 - val_accuracy: 0.9151 - val_loss: 0.2799\n",
      "Epoch 37/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.2649 - val_accuracy: 0.9073 - val_loss: 0.2705\n",
      "Epoch 38/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9162 - loss: 0.2485 - val_accuracy: 0.9035 - val_loss: 0.2672\n",
      "Epoch 39/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9126 - loss: 0.2682 - val_accuracy: 0.9073 - val_loss: 0.2708\n",
      "Epoch 40/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9116 - loss: 0.2693 - val_accuracy: 0.9112 - val_loss: 0.2642\n",
      "Epoch 41/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.2353 - val_accuracy: 0.9189 - val_loss: 0.2530\n",
      "Epoch 42/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9301 - loss: 0.2115 - val_accuracy: 0.9151 - val_loss: 0.2646\n",
      "Epoch 43/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8999 - loss: 0.2458 - val_accuracy: 0.9112 - val_loss: 0.2666\n",
      "Epoch 44/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.2087 - val_accuracy: 0.9228 - val_loss: 0.2618\n",
      "Epoch 45/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.2377 - val_accuracy: 0.9073 - val_loss: 0.2614\n",
      "Epoch 46/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8947 - loss: 0.2955 - val_accuracy: 0.9189 - val_loss: 0.2624\n",
      "Epoch 47/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9384 - loss: 0.1963 - val_accuracy: 0.9151 - val_loss: 0.2585\n",
      "Epoch 48/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.2238 - val_accuracy: 0.9228 - val_loss: 0.2525\n",
      "Epoch 49/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9222 - loss: 0.2239 - val_accuracy: 0.9151 - val_loss: 0.2652\n",
      "Epoch 50/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.1974 - val_accuracy: 0.9189 - val_loss: 0.2585\n",
      "Epoch 51/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2086 - val_accuracy: 0.9151 - val_loss: 0.2626\n",
      "Epoch 52/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.2158 - val_accuracy: 0.9266 - val_loss: 0.2546\n",
      "Epoch 53/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9104 - loss: 0.2122 - val_accuracy: 0.9189 - val_loss: 0.2460\n",
      "Epoch 54/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9082 - loss: 0.2392 - val_accuracy: 0.9112 - val_loss: 0.2640\n",
      "Epoch 55/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.1862 - val_accuracy: 0.9112 - val_loss: 0.2578\n",
      "Epoch 56/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9315 - loss: 0.1931 - val_accuracy: 0.9112 - val_loss: 0.2481\n",
      "Epoch 57/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2002 - val_accuracy: 0.9112 - val_loss: 0.2485\n",
      "Epoch 58/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.1626 - val_accuracy: 0.9112 - val_loss: 0.2634\n",
      "Epoch 59/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9427 - loss: 0.1595 - val_accuracy: 0.9189 - val_loss: 0.2517\n",
      "Epoch 60/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9278 - loss: 0.1784 - val_accuracy: 0.9151 - val_loss: 0.2541\n",
      "Epoch 61/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9393 - loss: 0.1744 - val_accuracy: 0.9073 - val_loss: 0.2636\n",
      "Epoch 62/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9216 - loss: 0.1922 - val_accuracy: 0.9189 - val_loss: 0.2504\n",
      "Epoch 63/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9466 - loss: 0.1691 - val_accuracy: 0.9228 - val_loss: 0.2434\n",
      "Epoch 64/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.1839 - val_accuracy: 0.9151 - val_loss: 0.2437\n",
      "Epoch 65/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9492 - loss: 0.1660 - val_accuracy: 0.9189 - val_loss: 0.2496\n",
      "Epoch 66/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9419 - loss: 0.1685 - val_accuracy: 0.9151 - val_loss: 0.2468\n",
      "Epoch 67/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9254 - loss: 0.1702 - val_accuracy: 0.9189 - val_loss: 0.2390\n",
      "Epoch 68/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9293 - loss: 0.1842 - val_accuracy: 0.9189 - val_loss: 0.2284\n",
      "Epoch 69/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 0.1584 - val_accuracy: 0.9266 - val_loss: 0.2403\n",
      "Epoch 70/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.1653 - val_accuracy: 0.9228 - val_loss: 0.2424\n",
      "Epoch 71/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9472 - loss: 0.1460 - val_accuracy: 0.9151 - val_loss: 0.2471\n",
      "Epoch 72/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9343 - loss: 0.1836 - val_accuracy: 0.9112 - val_loss: 0.2514\n",
      "Epoch 73/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1513 - val_accuracy: 0.9228 - val_loss: 0.2430\n",
      "Epoch 74/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.1563 - val_accuracy: 0.9189 - val_loss: 0.2406\n",
      "Epoch 75/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.1362 - val_accuracy: 0.9228 - val_loss: 0.2542\n",
      "Epoch 76/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.1311 - val_accuracy: 0.9228 - val_loss: 0.2428\n",
      "Epoch 77/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9429 - loss: 0.1545 - val_accuracy: 0.9228 - val_loss: 0.2425\n",
      "Epoch 78/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.1446 - val_accuracy: 0.9151 - val_loss: 0.2525\n",
      "Epoch 79/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.1362 - val_accuracy: 0.9151 - val_loss: 0.2681\n",
      "Epoch 80/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9447 - loss: 0.1417 - val_accuracy: 0.9151 - val_loss: 0.2633\n",
      "Epoch 81/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9608 - loss: 0.1322 - val_accuracy: 0.9189 - val_loss: 0.2568\n",
      "Epoch 82/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9500 - loss: 0.1310 - val_accuracy: 0.9151 - val_loss: 0.2456\n",
      "Epoch 83/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.1124 - val_accuracy: 0.9266 - val_loss: 0.2609\n",
      "Epoch 84/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9278 - loss: 0.1598 - val_accuracy: 0.9266 - val_loss: 0.2476\n",
      "Epoch 85/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9534 - loss: 0.1265 - val_accuracy: 0.9266 - val_loss: 0.2540\n",
      "Epoch 86/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.1170 - val_accuracy: 0.9266 - val_loss: 0.2561\n",
      "Epoch 87/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1184 - val_accuracy: 0.9228 - val_loss: 0.2486\n",
      "Epoch 88/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1254 - val_accuracy: 0.9305 - val_loss: 0.2462\n",
      "Epoch 89/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9588 - loss: 0.1163 - val_accuracy: 0.9228 - val_loss: 0.2678\n",
      "Epoch 90/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9540 - loss: 0.1193 - val_accuracy: 0.9266 - val_loss: 0.2505\n",
      "Epoch 91/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9351 - loss: 0.1475 - val_accuracy: 0.9266 - val_loss: 0.2693\n",
      "Epoch 92/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9386 - loss: 0.1679 - val_accuracy: 0.9305 - val_loss: 0.2518\n",
      "Epoch 93/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9465 - loss: 0.1497 - val_accuracy: 0.9266 - val_loss: 0.2506\n",
      "Epoch 94/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9479 - loss: 0.1263 - val_accuracy: 0.9228 - val_loss: 0.2603\n",
      "Epoch 95/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.1195 - val_accuracy: 0.9305 - val_loss: 0.2576\n",
      "Epoch 96/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9632 - loss: 0.1091 - val_accuracy: 0.9305 - val_loss: 0.2482\n",
      "Epoch 97/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9550 - loss: 0.1393 - val_accuracy: 0.9266 - val_loss: 0.2544\n",
      "Epoch 98/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9436 - loss: 0.1281 - val_accuracy: 0.9382 - val_loss: 0.2571\n",
      "Epoch 99/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9567 - loss: 0.1179 - val_accuracy: 0.9266 - val_loss: 0.2514\n",
      "Epoch 100/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1243 - val_accuracy: 0.9228 - val_loss: 0.2582\n",
      "Epoch 101/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.1299 - val_accuracy: 0.9305 - val_loss: 0.2632\n",
      "Epoch 102/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9602 - loss: 0.1027 - val_accuracy: 0.9305 - val_loss: 0.2558\n",
      "Epoch 103/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 0.1038 - val_accuracy: 0.9189 - val_loss: 0.2727\n",
      "Epoch 104/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.1277 - val_accuracy: 0.9228 - val_loss: 0.2695\n",
      "Epoch 105/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9583 - loss: 0.1201 - val_accuracy: 0.9228 - val_loss: 0.2644\n",
      "Epoch 106/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9578 - loss: 0.1104 - val_accuracy: 0.9189 - val_loss: 0.2516\n",
      "Epoch 107/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9579 - loss: 0.1242 - val_accuracy: 0.9228 - val_loss: 0.2765\n",
      "Epoch 108/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9618 - loss: 0.1003 - val_accuracy: 0.9228 - val_loss: 0.2681\n",
      "Epoch 109/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9615 - loss: 0.1217 - val_accuracy: 0.9228 - val_loss: 0.2751\n",
      "Epoch 110/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1206 - val_accuracy: 0.9112 - val_loss: 0.2561\n",
      "Epoch 111/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.1292 - val_accuracy: 0.9228 - val_loss: 0.2648\n",
      "Epoch 112/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9617 - loss: 0.1112 - val_accuracy: 0.9266 - val_loss: 0.2525\n",
      "Epoch 113/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9705 - loss: 0.1046 - val_accuracy: 0.9228 - val_loss: 0.2722\n",
      "Epoch 114/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9620 - loss: 0.1214 - val_accuracy: 0.9228 - val_loss: 0.2581\n",
      "Epoch 115/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9603 - loss: 0.1081 - val_accuracy: 0.9228 - val_loss: 0.2668\n",
      "Epoch 116/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.0955 - val_accuracy: 0.9266 - val_loss: 0.2646\n",
      "Epoch 117/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1076 - val_accuracy: 0.9266 - val_loss: 0.2700\n",
      "Epoch 118/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9567 - loss: 0.1038 - val_accuracy: 0.9228 - val_loss: 0.2640\n",
      "Epoch 119/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.1401 - val_accuracy: 0.9305 - val_loss: 0.2703\n",
      "Epoch 120/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9641 - loss: 0.1122 - val_accuracy: 0.9266 - val_loss: 0.2602\n",
      "Epoch 121/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.0998 - val_accuracy: 0.9228 - val_loss: 0.2793\n",
      "Epoch 122/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9611 - loss: 0.0892 - val_accuracy: 0.9266 - val_loss: 0.2835\n",
      "Epoch 123/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1251 - val_accuracy: 0.9151 - val_loss: 0.2732\n",
      "Epoch 124/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1119 - val_accuracy: 0.9228 - val_loss: 0.2608\n",
      "Epoch 125/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.1064 - val_accuracy: 0.9228 - val_loss: 0.2596\n",
      "Epoch 126/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9600 - loss: 0.0993 - val_accuracy: 0.9266 - val_loss: 0.2689\n",
      "Epoch 127/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1169 - val_accuracy: 0.9344 - val_loss: 0.2574\n",
      "Epoch 128/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.0996 - val_accuracy: 0.9266 - val_loss: 0.2584\n",
      "Epoch 129/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0861 - val_accuracy: 0.9266 - val_loss: 0.2736\n",
      "Epoch 130/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0869 - val_accuracy: 0.9305 - val_loss: 0.2522\n",
      "Epoch 131/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9651 - loss: 0.0851 - val_accuracy: 0.9228 - val_loss: 0.2572\n",
      "Epoch 132/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9653 - loss: 0.0844 - val_accuracy: 0.9266 - val_loss: 0.2721\n",
      "Epoch 133/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0802 - val_accuracy: 0.9266 - val_loss: 0.2719\n",
      "Epoch 134/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9652 - loss: 0.0939 - val_accuracy: 0.9189 - val_loss: 0.2771\n",
      "Epoch 135/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0754 - val_accuracy: 0.9228 - val_loss: 0.2880\n",
      "Epoch 136/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9584 - loss: 0.1102 - val_accuracy: 0.9266 - val_loss: 0.2780\n",
      "Epoch 137/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0648 - val_accuracy: 0.9266 - val_loss: 0.2848\n",
      "Epoch 138/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.0840 - val_accuracy: 0.9305 - val_loss: 0.2733\n",
      "Epoch 139/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9584 - loss: 0.0930 - val_accuracy: 0.9266 - val_loss: 0.2693\n",
      "Epoch 140/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.0836 - val_accuracy: 0.9266 - val_loss: 0.2644\n",
      "Epoch 141/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0788 - val_accuracy: 0.9266 - val_loss: 0.2651\n",
      "Epoch 142/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.0899 - val_accuracy: 0.9344 - val_loss: 0.2764\n",
      "Epoch 143/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9713 - loss: 0.0700 - val_accuracy: 0.9228 - val_loss: 0.2930\n",
      "Epoch 144/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9691 - loss: 0.0848 - val_accuracy: 0.9228 - val_loss: 0.2937\n",
      "Epoch 145/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.1247 - val_accuracy: 0.9266 - val_loss: 0.2664\n",
      "Epoch 146/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9673 - loss: 0.0960 - val_accuracy: 0.9266 - val_loss: 0.2610\n",
      "Epoch 147/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0680 - val_accuracy: 0.9266 - val_loss: 0.2709\n",
      "Epoch 148/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9711 - loss: 0.0813 - val_accuracy: 0.9266 - val_loss: 0.2658\n",
      "Epoch 149/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9709 - loss: 0.0936 - val_accuracy: 0.9228 - val_loss: 0.2797\n",
      "Epoch 150/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9684 - loss: 0.0928 - val_accuracy: 0.9305 - val_loss: 0.2636\n",
      "Epoch 151/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9586 - loss: 0.0992 - val_accuracy: 0.9305 - val_loss: 0.2735\n",
      "Epoch 152/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.0695 - val_accuracy: 0.9344 - val_loss: 0.2727\n",
      "Epoch 153/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.1001 - val_accuracy: 0.9305 - val_loss: 0.2863\n",
      "Epoch 154/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9597 - loss: 0.0957 - val_accuracy: 0.9344 - val_loss: 0.2980\n",
      "Epoch 155/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9752 - loss: 0.0864 - val_accuracy: 0.9305 - val_loss: 0.2768\n",
      "Epoch 156/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9660 - loss: 0.0977 - val_accuracy: 0.9266 - val_loss: 0.2920\n",
      "Epoch 157/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9693 - loss: 0.0843 - val_accuracy: 0.9228 - val_loss: 0.2805\n",
      "Epoch 158/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9607 - loss: 0.1110 - val_accuracy: 0.9228 - val_loss: 0.2878\n",
      "Epoch 159/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9649 - loss: 0.0819 - val_accuracy: 0.9305 - val_loss: 0.2844\n",
      "Epoch 160/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9728 - loss: 0.0803 - val_accuracy: 0.9266 - val_loss: 0.2837\n",
      "Epoch 161/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0696 - val_accuracy: 0.9266 - val_loss: 0.2848\n",
      "Epoch 162/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.0868 - val_accuracy: 0.9266 - val_loss: 0.2674\n",
      "Epoch 163/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9693 - loss: 0.0788 - val_accuracy: 0.9189 - val_loss: 0.2844\n",
      "Epoch 164/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.0738 - val_accuracy: 0.9266 - val_loss: 0.2788\n",
      "Epoch 165/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.0785 - val_accuracy: 0.9189 - val_loss: 0.3020\n",
      "Epoch 166/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.0870 - val_accuracy: 0.9266 - val_loss: 0.3029\n",
      "Epoch 167/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9636 - loss: 0.1006 - val_accuracy: 0.9228 - val_loss: 0.2979\n",
      "Epoch 168/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.0945 - val_accuracy: 0.9189 - val_loss: 0.2996\n",
      "Epoch 169/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9662 - loss: 0.0899 - val_accuracy: 0.9151 - val_loss: 0.2999\n",
      "Epoch 170/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9587 - loss: 0.0885 - val_accuracy: 0.9189 - val_loss: 0.2786\n",
      "Epoch 171/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9778 - loss: 0.0748 - val_accuracy: 0.9228 - val_loss: 0.2842\n",
      "Epoch 172/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9607 - loss: 0.0892 - val_accuracy: 0.9266 - val_loss: 0.2930\n",
      "Epoch 173/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0699 - val_accuracy: 0.9305 - val_loss: 0.2881\n",
      "Epoch 174/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0642 - val_accuracy: 0.9228 - val_loss: 0.3097\n",
      "Epoch 175/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9722 - loss: 0.0719 - val_accuracy: 0.9266 - val_loss: 0.3014\n",
      "Epoch 176/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9732 - loss: 0.0734 - val_accuracy: 0.9305 - val_loss: 0.2950\n",
      "Epoch 177/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.0743 - val_accuracy: 0.9305 - val_loss: 0.2935\n",
      "Epoch 178/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.0846 - val_accuracy: 0.9305 - val_loss: 0.2957\n",
      "Epoch 179/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9676 - loss: 0.0781 - val_accuracy: 0.9305 - val_loss: 0.2969\n",
      "Epoch 180/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9710 - loss: 0.0778 - val_accuracy: 0.9344 - val_loss: 0.2927\n",
      "Epoch 181/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9743 - loss: 0.0718 - val_accuracy: 0.9266 - val_loss: 0.3001\n",
      "Epoch 182/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9776 - loss: 0.0677 - val_accuracy: 0.9382 - val_loss: 0.3095\n",
      "Epoch 183/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.0643 - val_accuracy: 0.9344 - val_loss: 0.3107\n",
      "Epoch 184/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9680 - loss: 0.0722 - val_accuracy: 0.9305 - val_loss: 0.2965\n",
      "Epoch 185/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9700 - loss: 0.0719 - val_accuracy: 0.9344 - val_loss: 0.3051\n",
      "Epoch 186/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0688 - val_accuracy: 0.9228 - val_loss: 0.3143\n",
      "Epoch 187/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.0686 - val_accuracy: 0.9228 - val_loss: 0.3263\n",
      "Epoch 188/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9662 - loss: 0.0943 - val_accuracy: 0.9228 - val_loss: 0.3460\n",
      "Epoch 189/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9648 - loss: 0.0775 - val_accuracy: 0.9266 - val_loss: 0.3346\n",
      "Epoch 190/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0593 - val_accuracy: 0.9266 - val_loss: 0.3329\n",
      "Epoch 191/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0619 - val_accuracy: 0.9189 - val_loss: 0.3537\n",
      "Epoch 192/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9694 - loss: 0.0935 - val_accuracy: 0.9305 - val_loss: 0.3166\n",
      "Epoch 193/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.0905 - val_accuracy: 0.9112 - val_loss: 0.3216\n",
      "Epoch 194/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0638 - val_accuracy: 0.9228 - val_loss: 0.3207\n",
      "Epoch 195/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9785 - loss: 0.0642 - val_accuracy: 0.9305 - val_loss: 0.2833\n",
      "Epoch 196/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0617 - val_accuracy: 0.9305 - val_loss: 0.3090\n",
      "Epoch 197/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0760 - val_accuracy: 0.9382 - val_loss: 0.2861\n",
      "Epoch 198/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9634 - loss: 0.1005 - val_accuracy: 0.9266 - val_loss: 0.2763\n",
      "Epoch 199/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0553 - val_accuracy: 0.9305 - val_loss: 0.2849\n",
      "Epoch 200/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.0703 - val_accuracy: 0.9189 - val_loss: 0.3166\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.2084 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 94.44%\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Aldan\\AppData\\Local\\Temp\\tmpgeshssuc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Aldan\\AppData\\Local\\Temp\\tmpgeshssuc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Aldan\\AppData\\Local\\Temp\\tmpgeshssuc'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60), dtype=tf.float32, name='keras_tensor_6')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 36), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1891697955712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1890431386192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1890431397456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1890431388304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1890431400448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1890431520432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model berhasil dikonversi ke TFLite!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Simpan scaler\n",
    "\n",
    "def ubah_ke_fitur_rel(df):\n",
    "    kolom_xyz = [col for col in df.columns if col != \"label\"]\n",
    "    data = df[kolom_xyz].values.reshape(-1, 21, 3)  # 21 titik, 3 dimensi\n",
    "\n",
    "    fitur_baru = []\n",
    "    for baris in data:\n",
    "        anchor = baris[0]  # titik 0\n",
    "        rel = baris[1:] - anchor  # titik 1-20 relatif ke titik 0\n",
    "        fitur_baris = rel.flatten()  # jadi 60 elemen\n",
    "        fitur_baru.append(fitur_baris)\n",
    "\n",
    "    return np.array(fitur_baru)\n",
    "\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(r\"C:\\Users\\Aldan\\Desktop\\ASLClassification\\Code\\hand_features.csv\")  # Ganti dengan nama file kamu\n",
    "\n",
    "# 2. Pisahkan fitur dan label\n",
    "X = ubah_ke_fitur_rel(df)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# 3. Encode label\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded, num_classes=len(df[\"label\"].unique()))\n",
    "\n",
    "# 4. Normalisasi\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# 5. Split data ke training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Buat Neural Network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(36, activation='softmax')  # 36 kelas\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 7. Latih model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 8. Evaluasi\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Akurasi: {acc*100:.2f}%\")\n",
    "model.save(\"Model_ASL.h5\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Load model HDF5\n",
    "# model = tf.keras.models.load_model(r\"C:\\Users\\Aldan\\Desktop\\ASLClassification\\Code\\Model_ASL.h5\")\n",
    "\n",
    "# 2. Konversi ke TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# 3. Simpan ke file .tflite\n",
    "with open(\"model_klasifikasi.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model berhasil dikonversi ke TFLite!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ae53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Simpan scaler\n",
    "\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(r\"C:\\Users\\Aldan\\Desktop\\ASLClassification\\Code\\hand_features.csv\")  # Ganti dengan nama file kamu\n",
    "\n",
    "# 2. Pisahkan fitur dan label\n",
    "X = df.drop(\"label\", axis=1).values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# y_encoded = encoder.fit_transform(y)\n",
    "# y_categorical = to_categorical(y_encoded, num_classes=36)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "212bf6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8db5003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.6.2-cp310-cp310-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Using cached protobuf-4.25.8-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.2-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl.metadata (22 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.12 (from jax->mediapipe)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
      "  Downloading fonttools-4.58.5-cp310-cp310-win_amd64.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aldan\\miniconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Using cached mediapipe-0.10.21-cp310-cp310-win_amd64.whl (51.0 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Using cached protobuf-4.25.8-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached sounddevice-0.5.2-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached jax-0.6.2-py3-none-any.whl (2.7 MB)\n",
      "Using cached jaxlib-0.6.2-cp310-cp310-win_amd64.whl (57.9 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.5-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.5 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.6/7.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/7.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 6.9 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "Installing collected packages: sentencepiece, flatbuffers, pyparsing, pycparser, protobuf, pillow, opt_einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, opencv-contrib-python, ml_dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "\n",
      "   --- ------------------------------------  2/23 [pyparsing]\n",
      "   ----- ----------------------------------  3/23 [pycparser]\n",
      "   ----- ----------------------------------  3/23 [pycparser]\n",
      "   ------ ---------------------------------  4/23 [protobuf]\n",
      "   ------ ---------------------------------  4/23 [protobuf]\n",
      "   ------ ---------------------------------  4/23 [protobuf]\n",
      "   -------- -------------------------------  5/23 [pillow]\n",
      "   -------- -------------------------------  5/23 [pillow]\n",
      "   -------- -------------------------------  5/23 [pillow]\n",
      "   -------- -------------------------------  5/23 [pillow]\n",
      "   -------- -------------------------------  5/23 [pillow]\n",
      "   -------- -------------------------------  5/23 [pillow]\n",
      "   ---------- -----------------------------  6/23 [opt_einsum]\n",
      "  Attempting uninstall: numpy\n",
      "   ---------- -----------------------------  6/23 [opt_einsum]\n",
      "    Found existing installation: numpy 2.0.1\n",
      "   ---------- -----------------------------  6/23 [opt_einsum]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "    Uninstalling numpy-2.0.1:\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   ------------ ---------------------------  7/23 [numpy]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   --------------- ------------------------  9/23 [fonttools]\n",
      "   ------------------- -------------------- 11/23 [attrs]\n",
      "   -------------------- ------------------- 12/23 [absl-py]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ---------------------- ----------------- 13/23 [scipy]\n",
      "   ------------------------ --------------- 14/23 [opencv-contrib-python]\n",
      "   ------------------------ --------------- 14/23 [opencv-contrib-python]\n",
      "   ------------------------ --------------- 14/23 [opencv-contrib-python]\n",
      "   ------------------------ --------------- 14/23 [opencv-contrib-python]\n",
      "   ------------------------ --------------- 14/23 [opencv-contrib-python]\n",
      "   ------------------------ --------------- 14/23 [opencv-contrib-python]\n",
      "   --------------------------- ------------ 16/23 [contourpy]\n",
      "   ----------------------------- ---------- 17/23 [CFFI]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   --------------------------------- ------ 19/23 [matplotlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ---------------------------------- ----- 20/23 [jaxlib]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   ------------------------------------ --- 21/23 [jax]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   -------------------------------------- - 22/23 [mediapipe]\n",
      "   ---------------------------------------- 23/23 [mediapipe]\n",
      "\n",
      "Successfully installed CFFI-1.17.1 absl-py-2.3.1 attrs-25.3.0 contourpy-1.3.2 cycler-0.12.1 flatbuffers-25.2.10 fonttools-4.58.5 jax-0.6.2 jaxlib-0.6.2 kiwisolver-1.4.8 matplotlib-3.10.3 mediapipe-0.10.21 ml_dtypes-0.5.1 numpy-1.26.4 opencv-contrib-python-4.11.0.86 opt_einsum-3.4.0 pillow-11.3.0 protobuf-4.25.8 pycparser-2.22 pyparsing-3.2.3 scipy-1.15.3 sentencepiece-0.2.0 sounddevice-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Aldan\\AppData\\Local\\Temp\\pip-uninstall-x_ndhd0z'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
